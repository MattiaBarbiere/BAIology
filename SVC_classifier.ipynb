{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performs a dimensionality reduction before running SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from ipywidgets import AppLayout, TwoByTwoLayout, IntSlider, FloatSlider\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "# import ipywidgets as widgets\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# import umap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```make_pipe()```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a 3 step Pipeline given a list containing:\n",
    "-   `scaler`: Method for Preprocessing data or `None`\n",
    "-   `dim_reduction`: Dimensionality Reduction Method or `None`\n",
    "-   `clf`: Classifier\n",
    "Returns the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipe(steps, verbose=0):\n",
    "    \n",
    "    name = [\"scaler\", \"dim_reduction\", \"clf\"]\n",
    "    if steps[-1]==None:\n",
    "        raise ValueError(\"A model for SVC is needed\")\n",
    "    if len(steps)!=3:\n",
    "        raise ValueError(\"number of steps must be 3\")\n",
    "    \n",
    "    return Pipeline(steps=[(name[i], steps[i]) for i in range(3)], verbose=max(0,verbose-1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```clf()```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs a pipeline, on `data`, containing the 3 elements in the argument `steps`.\\\n",
    "Returns the fitted pipeline and prints the score on Test if `verbose`&ge;1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=RuntimeWarning)\n",
    "def clf(data, steps=None, verbose=True, seed=42):\n",
    "#>> Extracting data\n",
    "    X_train = data[\"train\"]\n",
    "    X_test = data[\"test\"]\n",
    "    y_train = data[\"y train\"]\n",
    "    y_test = data[\"y test\"]\n",
    "\n",
    "#>> Pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "                (\"scaler\", StandardScaler()), \n",
    "                (\"dim_reduction\", PCA(n_components=30, random_state=seed)),\n",
    "                (\"svc\", LinearSVC(random_state=seed)),\n",
    "                 ],\n",
    "                 verbose=verbose)\n",
    "    \n",
    "    if steps != None:\n",
    "        pipeline = make_pipe(steps, verbose=verbose)\n",
    "\n",
    "    pipeline.fit(X_train.T, y_train)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"{pipeline.score(X_test.T,y_test):.4f}\")\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```CVsearch()```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs Gridsearch and Cross validation to find the best parameters.\\\n",
    "Returns a DataFrame with informations of each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=(RuntimeWarning, ConvergenceWarning))\n",
    "def CVsearch(data, steps, cv_inner, param_grid=None, verbose=1):\n",
    "#>> Extracting data\n",
    "    X_train = data[\"train\"]\n",
    "    X_test = data[\"test\"]\n",
    "    y_train = data[\"y train\"]\n",
    "    y_test = data[\"y test\"]\n",
    "    max_dim = data[\"max dim\"]\n",
    "\n",
    "#>> Pipeline\n",
    "    pipe = make_pipe(steps)\n",
    "\n",
    "#>> Search and CV\n",
    "    dim=(max_dim//cv_inner)*(cv_inner-1)\n",
    "\n",
    "    if param_grid==None:\n",
    "        param_grid ={\n",
    "                    \"dim_reduction__n_components\": [dim for dim in range(100, dim, 100)],\n",
    "                    \"clf__C\": [0.001, 0.01, 0.1, 1],\n",
    "                } \n",
    "    \n",
    "    clf = GridSearchCV(pipe, param_grid, cv=cv_inner, verbose=verbose-2, refit=True)\n",
    "    clf.fit(X_train.T, y_train)\n",
    "\n",
    "#>> Output\n",
    "    table = pd.DataFrame(clf.cv_results_)\n",
    "    i = clf.best_index_\n",
    "    best = table[i:i+1]\n",
    "    cv_results = pd.concat((best.set_index('rank_test_score'),table.drop(index=i).set_index('rank_test_score').sort_index()))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"best parameters: {clf.best_params_}\")\n",
    "        print(f\"best score: {clf.best_score_:.3f}\")\n",
    "        print(f\"prediction score: {clf.score(X_test.T, y_test):.3f}\")\n",
    "        print(f\"F1 score: {f1_score(y_test, clf.predict(X_test.T)):.3f}\")\n",
    "        if verbose-1:\n",
    "            display(cv_results.head(4))\n",
    "\n",
    "    return clf, cv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ignore_warnings(category=(RuntimeWarning, ConvergenceWarning))\n",
    "# def CVsearch(X, y, steps, cv_inner, cv_outer=5, param_grid=None, verbose=1):\n",
    "# #>> Pipeline\n",
    "#     pipe = make_pipe(steps)\n",
    "\n",
    "# #>> Search and CV\n",
    "#     max_dim = min(X.shape)\n",
    "#     dim=(max_dim//cv_inner)*(cv_inner-1)\n",
    "\n",
    "#     if param_grid==None:\n",
    "#         param_grid ={\n",
    "#                     \"dim_reduction__n_components\": [dim for dim in range(100, dim, 100)],\n",
    "#                     \"clf__C\": [0.001, 0.01, 0.1, 1],\n",
    "#                 } \n",
    "    \n",
    "#     clf = GridSearchCV(pipe, param_grid, cv=cv_inner, verbose=verbose-1, refit=True)\n",
    "#     clf.fit(X.T, y)\n",
    "\n",
    "# #>> Output\n",
    "#     table = pd.DataFrame(clf.cv_results_)\n",
    "#     i = clf.best_index_\n",
    "#     best = table[i:i+1]\n",
    "#     cv_results = pd.concat((best.set_index('rank_test_score'),table.drop(index=i).set_index('rank_test_score').sort_index()))\n",
    "\n",
    "#     if verbose:\n",
    "#         print(f\"best parameters: {clf.best_params_}\")\n",
    "#         print(f\"best score: {clf.best_score_:.3f}\")\n",
    "#         print(f\"prediction score: {cross_val_score(clf, X=X.T, y=y, cv=cv_outer).mean():.3f}\")\n",
    "#         display(cv_results.head(4))\n",
    "\n",
    "#     return cv_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
