{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processes data in Raw folder and stores them in Data folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `process_raw()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates both a test and a train dataset in `SmartS_data` or `DropSeq_data` respectively, with of shape: (*n_features*, *n_samples*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw(section=\"SmartS\", test_size=0.20, seed=42):\n",
    "\n",
    "    ignore=\"\"\n",
    "    name = \"_SmartS\"\n",
    "    if section == \"DropSeq\":\n",
    "        ignore = \"_ignore\"\n",
    "        name = \"\"\n",
    "\n",
    "    HCC = pd.read_csv(f\"{section}_raw{ignore}/HCC1806{name}_Filtered_Normalised_3000_Data_train.txt\", delimiter=\"\\ \",engine='python',index_col=0)\n",
    "    MCF = pd.read_csv(f\"{section}_raw{ignore}/MCF7{name}_Filtered_Normalised_3000_Data_train.txt\", delimiter=\"\\ \",engine='python',index_col=0)\n",
    "\n",
    "    HCC_train, HCC_test = train_test_split(HCC.T, test_size=test_size, random_state=seed)\n",
    "    MCF_train, MCF_test = train_test_split(MCF.T, test_size=test_size, random_state=seed)\n",
    "\n",
    "    HCC_train.T.to_csv(f\"{section}_data/HCC1806_{section}_Filtered_Normalised_3000_Data_train.txt\", sep=\" \", quoting=csv.QUOTE_NONE)\n",
    "    HCC_test.T.to_csv(f\"{section}_data/HCC1806_{section}_Filtered_Normalised_3000_Data_test.txt\", sep=\" \", quoting=csv.QUOTE_NONE)\n",
    "    MCF_train.T.to_csv(f\"{section}_data/MCF7_{section}_Filtered_Normalised_3000_Data_train.txt\", sep=\" \", quoting=csv.QUOTE_NONE)\n",
    "    MCF_test.T.to_csv(f\"{section}_data/MCF7_{section}_Filtered_Normalised_3000_Data_test.txt\", sep=\" \", quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `data_split()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns Train and Test `pandas.DataFrame` along with `max_dim` and their true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(file='MCF7',section=\"SmartS\"):\n",
    "#>> Import, Rename, Cleaning Data (Missing XCells train data)\n",
    "    def renamer(name, section=section):\n",
    "        class_position = {\"SmartS\":-3, \"DropSeq\":-1}\n",
    "        classification = name.split(\"_\")[class_position[section]] #change -1 into -3\n",
    "        cell = name.split(\"_\")[-2]\n",
    "        if len(classification) > 4:\n",
    "            classification = classification[:4]\n",
    "        return classification+\"_\"+cell\n",
    "\n",
    "    # Train\n",
    "    filepath_Train = f\"{section}_data/{file}_{section}_Filtered_Normalised_3000_Data_train.txt\" # remove \"(DropSeq)\"\n",
    "    pd_Train = pd.read_csv(filepath_Train,delimiter=\" \",index_col=0).astype('float32')\n",
    "    pd_Train.rename(mapper=renamer, axis='columns', inplace=True)\n",
    "    pd_Train.dropna(axis='rows', inplace = True)\n",
    "    # print(df_Train.shape)\n",
    "    pd_y_Train = [int(i.split(\"_\")[0]=='Norm') for i in pd_Train.columns]\n",
    "\n",
    "    # Test\n",
    "    filepath_Test = f\"{section}_data/{file}_{section}_Filtered_Normalised_3000_Data_test.txt\" # remove \"(DropSeq)\"\n",
    "    pd_Test = pd.read_csv(filepath_Test,delimiter=\" \",index_col=0).astype('float32')\n",
    "    pd_Test.rename(mapper=renamer, axis='columns', inplace=True)\n",
    "    pd_Test.dropna(axis='rows', inplace = True)\n",
    "    # print(df_Test.shape)\n",
    "    pd_y_Test = [int(i.split(\"_\")[0]=='Norm') for i in pd_Test.columns]\n",
    "\n",
    "    max_dim = min(pd_Train.shape)\n",
    "\n",
    "    data = {\"train\":pd_Train, \"test\":pd_Test, \"max dim\":max_dim, \"y train\":pd_y_Train, \"y test\":pd_y_Test}\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```data_loader()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(file='MCF7',section=\"SmartS\"):\n",
    "#>> Import, Rename, Cleaning Data (Missing XCells train data)\n",
    "    def renamer(name, section=section):\n",
    "        class_position = {\"SmartS\":-3, \"DropSeq\":-1}\n",
    "        classification = name.split(\"_\")[class_position[section]] #change -1 into -3\n",
    "        cell = name.split(\"_\")[-2]\n",
    "        if len(classification) > 4:\n",
    "            classification = classification[:4]\n",
    "        return classification+\"_\"+cell\n",
    "\n",
    "    ignore=\"\"\n",
    "    name = \"_SmartS\"\n",
    "    if section == \"DropSeq\":\n",
    "        ignore = \"_ignore\"\n",
    "        name = \"\"\n",
    "\n",
    "    # Set\n",
    "    filepath_X = f\"{section}_raw{ignore}/{file}{name}_Filtered_Normalised_3000_Data_train.txt\"\n",
    "    X = pd.read_csv(filepath_X,delimiter=\" \",index_col=0).astype('float32')\n",
    "    X.rename(mapper=renamer, axis='columns', inplace=True)\n",
    "    X.dropna(axis='rows', inplace = True)\n",
    "    y = [int(i.split(\"_\")[0]=='Norm') for i in X.columns]\n",
    "\n",
    "    return X, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
