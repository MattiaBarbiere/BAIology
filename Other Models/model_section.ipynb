{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sketches "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dataset\n",
    "`MCF7_SmartS_Filtered_Normalised_3000_Data_train.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath_Train = \"raw_data\\MCF7_SmartS_Filtered_Normalised_3000_Data_train.txt\"\n",
    "# df_Train = pd.read_csv(filepath_Train,delimiter=\"\\ \",engine='python',index_col=0)\n",
    "# print(\"Dataframe dimensions:\", np.shape(df_Train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypo/Norm Classification DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #List of all cells that were part of the hypoxia and normoxia groups\n",
    "# hypo = []\n",
    "# norm = []\n",
    "# for cell in df_Train.columns:\n",
    "#     if \"Hypo\" in cell.split(\"_\"):\n",
    "#         hypo.append(cell)\n",
    "#     elif \"Norm\" in cell.split(\"_\"):\n",
    "#             norm.append(cell)\n",
    "#     else:\n",
    "#         print(\"Unkown:\", cell)\n",
    "\n",
    "# print(\"Hypo:\", len(hypo), \"Norm:\", len(norm))\n",
    "\n",
    "# #Data sets that contain only hypoxia cells\n",
    "# df_Hypo = df_Train[hypo]\n",
    "# #Data sets that contain only hypoxia cells\n",
    "# df_Norm = df_Train[norm]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline\n",
    "Parameters:\n",
    "- `C` = 1\n",
    "- `loss` = hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene1=df_Hypo.index[0]\n",
    "# Gene2=df_Hypo.index[1]\n",
    "# print(\"Genes of interest are:\"+Gene1+\" & \"+Gene2)\n",
    "\n",
    "# A=df_Hypo.loc[Gene1].tolist()+df_Norm.loc[Gene1].tolist()\n",
    "# B=df_Hypo.loc[Gene2].tolist()+df_Norm.loc[Gene2].tolist()\n",
    "# X = [list(i) for i in zip(A,B)]\n",
    "# y = [0 for i in range(len(df_Hypo.iloc[0,:].tolist()))]+[1 for i in range(len(df_Norm.iloc[0,:].tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import numpy as np\n",
    "# # from sklearn.pipeline import Pipeline\n",
    "# # from sklearn.preprocessing import StandardScaler\n",
    "# # from sklearn.svm import LinearSVC\n",
    "\n",
    "# C = 1\n",
    "\n",
    "# svm_clf = Pipeline((\n",
    "#         (\"scaler\", StandardScaler()),\n",
    "#         (\"linear_svc\", LinearSVC(C=C, loss=\"hinge\")),\n",
    "#     ))\n",
    "# print(X)\n",
    "# print(y)\n",
    "# clf = svm_clf.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on Training Set (Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Outliers finder\n",
    "# output = svm_clf.predict(X)\n",
    "# outlier = []\n",
    "# for i in range(len(df_Hypo.iloc[0,:].tolist())):\n",
    "#     if output[i]!=0:\n",
    "#         outlier.append(i+1)\n",
    "# print(\"Outliers: {}\".format(outlier))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Graphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph option 1\n",
    "`To Be Fixed` : The boundary lines are limited only to the first quadrant for some reason \\\n",
    "`Observation` : number of outliers (misplaced blue triangles) in the graph matches the number found above (19 when C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# # decision_function = clf.decision_function(X)\n",
    "# # support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\n",
    "# # support_vectors = Xnp[support_vector_indices]\n",
    "# Xnp = np.array(X)\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.cla()\n",
    "\n",
    "# # plt.scatter(Xnp[:, 0], Xnp[:, 1], c=y, s=10, cmap=plt.cm.Paired)\n",
    "# plt.scatter(Xnp[len(df_Hypo.iloc[0,:].tolist()):, 0], Xnp[len(df_Hypo.iloc[0,:].tolist()):, 1], c='g', s=10, marker=\"s\", label='Normoxia')\n",
    "# plt.scatter(Xnp[:len(df_Hypo.iloc[0,:].tolist()), 0], Xnp[:len(df_Hypo.iloc[0,:].tolist()), 1], c='b', s=10, marker=\"^\", label='Hypoxia')\n",
    "\n",
    "\n",
    "# ax = plt.gca()\n",
    "\n",
    "# DecisionBoundaryDisplay.from_estimator(\n",
    "#     clf,\n",
    "#     Xnp,\n",
    "#     ax=ax,\n",
    "#     grid_resolution=50,\n",
    "#     plot_method=\"contour\",\n",
    "#     colors=\"k\",\n",
    "#     levels=[-1, 0, 1],\n",
    "#     alpha=0.5,\n",
    "#     linestyles=[\"--\", \"-\", \"--\"],\n",
    "# )\n",
    "# # plt.scatter(      #highlights support vector\n",
    "# #     support_vectors[:, 0],\n",
    "# #     support_vectors[:, 1],\n",
    "# #     s=50,\n",
    "# #     linewidth=1,\n",
    "# #     facecolors=\"red\",\n",
    "# #     alpha=.1,\n",
    "# #     edgecolors=\"r\",\n",
    "# # )\n",
    "# plt.title(\"C=\"+str(C))\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# # Organazing 2 dataset (Hypo & Norm) in np.arrays of 2 dimensions (Gene1 & Gene2)\n",
    "# np_Hypo = df_Hypo.loc[[Gene1,Gene2]].to_numpy().transpose()\n",
    "# np_Norm = df_Norm.loc[[Gene1,Gene2]].to_numpy().transpose()\n",
    "# np_Data = np.concatenate((np_Hypo,np_Norm))\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.cla()\n",
    "\n",
    "\n",
    "# ax = plt.gca()\n",
    "\n",
    "# DecisionBoundaryDisplay.from_estimator(\n",
    "#     clf,\n",
    "#     np_Data,\n",
    "#     eps = 10,\n",
    "#     ax=ax,\n",
    "#     grid_resolution=50,\n",
    "#     plot_method=\"contour\",\n",
    "#     colors=\"k\",\n",
    "#     levels=[-1, 0, 1],\n",
    "#     alpha=0.5,\n",
    "#     linestyles=[\"--\", \"-\", \"--\"],\n",
    "# )\n",
    "\n",
    "# plt.scatter(np_Norm[:, 0], np_Norm[:, 1], c='g', s=10, marker=\"s\", label='Normoxia')\n",
    "# plt.scatter(np_Hypo[:, 0], np_Hypo[:, 1], c='b', s=10, marker=\"^\", label='Hypoxia')\n",
    "\n",
    "\n",
    "# plt.title(\"C=\"+str(C))\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# print(\"Number of outliers: \"+str(len(outlier)))\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ~~Graph option 2~~\n",
    "`Issues` : For some reasons does not draw the hyperplane but there is an dot in the negative y-axis\n",
    "`Update` : The dot at (0,-745) is actually a line, possibly the one missing \\\n",
    "`Update2` : Running the script causes problem in the other graphs when re-running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib\n",
    "# from matplotlib import pyplot as plt\n",
    "# import scipy\n",
    "# from sklearn import svm\n",
    "\n",
    "# mu_vec1 = np.array([0,0])\n",
    "# cov_mat1 = np.array([[2,0],[0,2]])\n",
    "# x1_samples = np.random.multivariate_normal(mu_vec1, cov_mat1, 100)\n",
    "# mu_vec1 = mu_vec1.reshape(1,2).T # to 1-col vector\n",
    "\n",
    "# mu_vec2 = np.array([1,2])\n",
    "# cov_mat2 = np.array([[1,0],[0,1]])\n",
    "# x2_samples = np.random.multivariate_normal(mu_vec2, cov_mat2, 100)\n",
    "# mu_vec2 = mu_vec2.reshape(1,2).T\n",
    "\n",
    "\n",
    "# fig = plt.figure(3)\n",
    "\n",
    "\n",
    "# # plt.scatter(x1_samples[:,0],x1_samples[:,1], marker='+')\n",
    "# # plt.scatter(x2_samples[:,0],x2_samples[:,1], c= 'green', marker='o')\n",
    "# plt.scatter(Xnp[:len(df_Hypo.iloc[0,:].tolist()), 0], Xnp[:len(df_Hypo.iloc[0,:].tolist()), 1], c='b', s=10, marker=\"^\", label='Hypoxia')\n",
    "# plt.scatter(Xnp[len(df_Hypo.iloc[0,:].tolist()):, 0], Xnp[len(df_Hypo.iloc[0,:].tolist()):, 1], c='g', s=10, marker=\"s\", label='Normoxia')\n",
    "\n",
    "\n",
    "# # X = np.concatenate((x1_samples,x2_samples), axis = 0)\n",
    "# # Y = np.array([0]*100 + [1]*100)\n",
    "\n",
    "# C = 1.0  # SVM regularization parameter\n",
    "# clf = svm.SVC(kernel = 'linear',  gamma=0.7, C=C )\n",
    "# clf.fit(X, y)\n",
    "\n",
    "# w = clf.coef_[0]\n",
    "# a = -w[0] / w[1]\n",
    "# xx = np.linspace(-5, 5)\n",
    "# yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "\n",
    "# plt.plot(xx, yy, 'k-')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVC\n",
    "`Issues`: \n",
    "-   With values of `C`>10 it may output the following warning `ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.`\n",
    "-   Difficulty in obtaining the support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Linear_SVC(c=1,file='MCF7'):\n",
    "# #>> Import Data (Missing XCells train data)\n",
    "#     filepath_Train = \"raw_data\\\\\"+file+\"_SmartS_Filtered_Normalised_3000_Data_train.txt\"\n",
    "#     df_Train = pd.read_csv(filepath_Train,delimiter=\"\\ \",engine='python',index_col=0)\n",
    "\n",
    "# #>> List of all cells that were part of the hypoxia and normoxia groups\n",
    "#     hypo = []\n",
    "#     norm = []\n",
    "#     if file=='MCF7':\n",
    "#         for cell in df_Train.columns:\n",
    "#             if \"Hypo\" in cell.split(\"_\"):\n",
    "#                 hypo.append(cell)\n",
    "#             elif \"Norm\" in cell.split(\"_\"):\n",
    "#                 norm.append(cell)\n",
    "#             else:\n",
    "#                 print(\"Unkown: \"+str(cell))\n",
    "#     elif file=='HCC1806':\n",
    "#         for cell in df_Train.columns:\n",
    "#             if \"Hypoxia\" in cell.split(\"_\"):\n",
    "#                 hypo.append(cell)\n",
    "#             elif \"Normoxia\" in cell.split(\"_\"):\n",
    "#                 norm.append(cell)\n",
    "#             else:\n",
    "#                 print(\"Unkown: \"+str(cell))\n",
    "\n",
    "#     #Data sets that contain only hypoxia cells\n",
    "#     df_Hypo = df_Train[hypo]\n",
    "#     #Data sets that contain only hypoxia cells\n",
    "#     df_Norm = df_Train[norm] \n",
    "\n",
    "# #>> Pipeline\n",
    "#     Gene1=df_Hypo.index[0]\n",
    "#     Gene2=df_Hypo.index[1]\n",
    "#     # print(\"> Genes of interest are:\"+Gene1+\" & \"+Gene2)\n",
    "\n",
    "#     A=df_Hypo.loc[Gene1].tolist()+df_Norm.loc[Gene1].tolist()\n",
    "#     B=df_Hypo.loc[Gene2].tolist()+df_Norm.loc[Gene2].tolist()\n",
    "#     X = [list(i) for i in zip(A,B)]\n",
    "#     y = [0 for i in range(len(df_Hypo.iloc[0,:].tolist()))]+[1 for i in range(len(df_Norm.iloc[0,:].tolist()))]\n",
    "\n",
    "#     svm_clf = Pipeline((\n",
    "#             (\"scaler\", StandardScaler()),\n",
    "#             (\"linear_svc\", LinearSVC(C=c, loss=\"hinge\")),\n",
    "#         ))\n",
    "#     clf = svm_clf.fit(X, y)\n",
    "\n",
    "# #>> Outliers finder\n",
    "#     output = svm_clf.predict(X)\n",
    "#     outlier = []\n",
    "#     for i in range(len(df_Hypo.iloc[0,:].tolist())):\n",
    "#         if output[i]!=0:\n",
    "#             outlier.append(i+1)\n",
    "#     # print(\"> {} outliers: {}\".format(len(outlier),outlier))\n",
    "    \n",
    "# #>> Graph\n",
    "\n",
    "#     # Organazing 2 dataset (Hypo & Norm) in np.arrays of 2 dimensions (Gene1 & Gene2)\n",
    "#     np_Hypo = df_Hypo.loc[[Gene1,Gene2]].to_numpy().transpose()\n",
    "#     np_Norm = df_Norm.loc[[Gene1,Gene2]].to_numpy().transpose()\n",
    "#     np_Data = np.concatenate((np_Hypo,np_Norm))\n",
    "\n",
    "#     fig = plt.figure('LinearSVC')\n",
    "#     plt.cla()\n",
    "\n",
    "#     ax = plt.gca()\n",
    "\n",
    "#     DecisionBoundaryDisplay.from_estimator(\n",
    "#         clf,\n",
    "#         np_Data,\n",
    "#         eps = 10,\n",
    "#         ax=ax,\n",
    "#         grid_resolution=50,\n",
    "#         plot_method=\"contour\",\n",
    "#         colors=\"k\",\n",
    "#         levels=[-1, 0, 1],\n",
    "#         alpha=0.5,\n",
    "#         linestyles=[\"--\", \"-\", \"--\"],\n",
    "#     )\n",
    "\n",
    "\n",
    "#     # decision_function = clf.decision_function(X)\n",
    "#     # support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\n",
    "#     # support_vectors = np.array(X)[support_vector_indices]\n",
    "    \n",
    "#     # np_Norm_diff = np.array([pt for pt in np_Norm if pt not in support_vectors])\n",
    "#     # np_Hypo_diff = np.array([pt for pt in np_Hypo if pt not in support_vectors])\n",
    "\n",
    "#     # plt.scatter(      #highlights support vector\n",
    "#     # support_vectors[:, 0],\n",
    "#     # support_vectors[:, 1],\n",
    "#     # s=50,\n",
    "#     # linewidth=1,\n",
    "#     # facecolors=\"red\",\n",
    "#     # alpha=.1,\n",
    "#     # edgecolors=\"r\",\n",
    "#     # )\n",
    "\n",
    "#     plt.scatter(np_Norm[:, 0], np_Norm[:, 1], c='g', s=10, marker=\"s\", label='Normoxia')\n",
    "#     plt.scatter(np_Hypo[:, 0], np_Hypo[:, 1], c='b', s=10, marker=\"^\", label='Hypoxia')\n",
    "\n",
    "\n",
    "#     # plt.scatter(np_Norm_diff[:, 0], np_Norm_diff[:, 1], c='g', s=10, marker=\"s\", label='Normoxia')\n",
    "#     # plt.scatter(np_Hypo_diff[:, 0], np_Hypo_diff[:, 1], c='b', s=10, marker=\"^\", label='Hypoxia')\n",
    "#     # plt.scatter(support_vectors[:, 0], support_vectors[:, 1], c='r', s=10, marker=\"*\", label='Support Vectors')\n",
    "\n",
    "\n",
    "#     # Norm_supp = []\n",
    "#     # Norm = np_Norm.tolist()\n",
    "#     # for pt in Norm:\n",
    "#     #     if pt in support_vectors:\n",
    "#     #         Norm_supp.append(pt)\n",
    "#     #         Norm.remove(pt)\n",
    "#     # plt.scatter(np.array(Norm)[:, 0], np.array(Norm)[:, 1], c='g', s=20, marker=\"s\", label='Normoxia')\n",
    "#     # plt.scatter(np.array(Norm_supp)[:, 0], np.array(Norm_supp)[:, 1], c='g', s=20, marker=\"s\", edgecolors='r')\n",
    "    \n",
    "#     # Hypo_supp = []\n",
    "#     # Hypo = np_Hypo.tolist()\n",
    "#     # for pt in Hypo:\n",
    "#     #     if pt in support_vectors:\n",
    "#     #         Hypo_supp.append(pt)\n",
    "#     #         Hypo.remove(pt)\n",
    "#     # plt.scatter(np.array(Hypo)[:, 0], np.array(Hypo)[:, 1], c='b', s=20, marker=\"^\", label='Hypoxia')\n",
    "#     # plt.scatter(np.array(Hypo_supp)[:, 0], np.array(Hypo_supp)[:, 1], c='b', s=20, marker=\"^\", edgecolors='r')\n",
    "\n",
    "\n",
    "#     ax.set_xlabel(Gene1)\n",
    "#     ax.set_ylabel(Gene2)\n",
    "#     plt.title(\"C=\"+str(c))\n",
    "\n",
    "#     plt.legend()\n",
    "#     return {'graph':fig, 'outlier': outlier}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Widget Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def widget_Linear_SVC(): \n",
    "#     plt.ioff()\n",
    "\n",
    "#     dropdown = widgets.Dropdown(\n",
    "#         options=['HCC1806', 'MCF7', 'XCells'],\n",
    "#         value='MCF7',\n",
    "#         description='File:',\n",
    "#     )\n",
    "\n",
    "#     slider = FloatSlider(\n",
    "#         orientation='horizontal',\n",
    "#         description='C value:',\n",
    "#         value=1,\n",
    "#         min=0.2,\n",
    "#         max=100,\n",
    "#         step=0.2\n",
    "#     )\n",
    "\n",
    "#     out = widgets.Output()\n",
    "\n",
    "#     slider.layout.width = '40%'\n",
    "\n",
    "#     svm_output = Linear_SVC(c=slider.value)\n",
    "#     fig = svm_output['graph']\n",
    "#     with out:\n",
    "#         print(str(len(svm_output['outlier']))+\" outliers: {}\".format(svm_output['outlier']))\n",
    "#     fig.canvas.resizable = False\n",
    "#     # fig.canvas.header_visible = False\n",
    "#     # fig.canvas.toolbar_position = 'top'\n",
    "#     fig.canvas.layout.min_height = '400px'\n",
    "#     plt.title(dropdown.value+' & C = {}'.format(slider.value))\n",
    "\n",
    "#     def update_lines(change):\n",
    "#         outlier = Linear_SVC(c=change.new, file=dropdown.value)['outlier']\n",
    "#         out.clear_output()\n",
    "#         with out:\n",
    "#             print(str(len(outlier))+\" outliers: {}\".format(outlier))\n",
    "#         plt.title(dropdown.value+' & C = {}'.format(change.new))\n",
    "#         fig.canvas.draw()\n",
    "#         fig.canvas.flush_events()\n",
    "\n",
    "#     def update_file(change):\n",
    "#         if change.new == 'XCells':\n",
    "#             out.clear_output()\n",
    "#             dropdown.value = change.old\n",
    "#             with out:\n",
    "#                 print(\"\\n! - '\"+change.new+\"' file missing in folder 'raw_data\\\\' - !\\n\")\n",
    "#             return\n",
    "#         outlier = Linear_SVC(c=slider.value, file=change.new)['outlier']\n",
    "#         out.clear_output()\n",
    "#         with out:\n",
    "#             print(str(len(outlier))+\" outliers: {}\".format(outlier))\n",
    "#         plt.title(change.new+' & C = {}'.format(slider.value))\n",
    "#         fig.canvas.draw()\n",
    "#         fig.canvas.flush_events()\n",
    "\n",
    "#     slider.observe(update_lines, names='value')\n",
    "#     dropdown.observe(update_file, names='value')\n",
    "\n",
    "#     layout = AppLayout(\n",
    "#         header=dropdown,\n",
    "#         left_sidebar=fig.canvas,\n",
    "#         center=out,\n",
    "#         footer=slider,\n",
    "#         pane_heights=[0, 6, 1],\n",
    "#         pane_widths=[6, 6, 3]\n",
    "#     )\n",
    "#     display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget_Linear_SVC()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from ipywidgets import AppLayout, IntSlider, FloatSlider\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import clear_output\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC\n",
    "based on svm.SVC, it is more powerfull than `LinearSVC` since it allows for non linear kernel. \\\n",
    "Moreover it can reproduce the previous function by setting `kernel`='linear' , like in this case. \\\n",
    "Works only on 2 Genes, no Issues so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _SVC(c=1,file='MCF7'):\n",
    "# #>> Import Data (Missing XCells train data)\n",
    "#     filepath_Train = \"raw_data\\\\\"+file+\"_SmartS_Filtered_Normalised_3000_Data_train.txt\"\n",
    "#     df_Train = pd.read_csv(filepath_Train,delimiter=\"\\ \",engine='python',index_col=0)\n",
    "\n",
    "# #>> List of all cells that were part of the hypoxia and normoxia groups\n",
    "#     hypo = []\n",
    "#     norm = []\n",
    "#     if file=='MCF7':\n",
    "#         for cell in df_Train.columns:\n",
    "#             if \"Hypo\" in cell.split(\"_\"):\n",
    "#                 hypo.append(cell)\n",
    "#             elif \"Norm\" in cell.split(\"_\"):\n",
    "#                 norm.append(cell)\n",
    "#             else:\n",
    "#                 print(\"Unkown: \"+str(cell))\n",
    "#     elif file=='HCC1806':\n",
    "#         for cell in df_Train.columns:\n",
    "#             if \"Hypoxia\" in cell.split(\"_\"):\n",
    "#                 hypo.append(cell)\n",
    "#             elif \"Normoxia\" in cell.split(\"_\"):\n",
    "#                 norm.append(cell)\n",
    "#             else:\n",
    "#                 print(\"Unkown: \"+str(cell))\n",
    "\n",
    "#     #Data sets that contain only hypoxia cells\n",
    "#     df_Hypo = df_Train[hypo]\n",
    "#     #Data sets that contain only hypoxia cells\n",
    "#     df_Norm = df_Train[norm] \n",
    "\n",
    "# #>> Pipeline\n",
    "#     Gene1=df_Hypo.index[0]\n",
    "#     Gene2=df_Hypo.index[1]\n",
    "#     # print(\"> Genes of interest are:\"+Gene1+\" & \"+Gene2)\n",
    "\n",
    "#     A=df_Hypo.loc[Gene1].tolist()+df_Norm.loc[Gene1].tolist()\n",
    "#     B=df_Hypo.loc[Gene2].tolist()+df_Norm.loc[Gene2].tolist()\n",
    "#     X = [list(i) for i in zip(A,B)]\n",
    "#     y = [0 for i in range(len(df_Hypo.iloc[0,:].tolist()))]+[1 for i in range(len(df_Norm.iloc[0,:].tolist()))]\n",
    "\n",
    "#     svm_clf = Pipeline((\n",
    "#             (\"scaler\", StandardScaler()),\n",
    "#             (\"linear_svc\", SVC(C=c, kernel='linear')),\n",
    "#         ))\n",
    "#     clf = svm_clf.fit(X, y)\n",
    "\n",
    "# #>> Outliers finder\n",
    "#     output = svm_clf.predict(X)\n",
    "#     outlier = []\n",
    "#     for i in range(len(df_Hypo.iloc[0,:].tolist())):\n",
    "#         if output[i]!=0:\n",
    "#             outlier.append(i+1)\n",
    "#     # print(\"> {} outliers: {}\".format(len(outlier),outlier))\n",
    "    \n",
    "# #>> Graph\n",
    "\n",
    "#     # Organazing 2 dataset (Hypo & Norm) in np.arrays of 2 dimensions (Gene1 & Gene2)\n",
    "#     np_Hypo = df_Hypo.loc[[Gene1,Gene2]].to_numpy().transpose()\n",
    "#     np_Norm = df_Norm.loc[[Gene1,Gene2]].to_numpy().transpose()\n",
    "#     np_Data = np.concatenate((np_Hypo,np_Norm))\n",
    "\n",
    "#     fig = plt.figure('svm.SVC')\n",
    "#     plt.cla()\n",
    "\n",
    "#     ax = plt.gca()\n",
    "\n",
    "#     DecisionBoundaryDisplay.from_estimator(\n",
    "#         clf,\n",
    "#         np_Data,\n",
    "#         eps = 10,\n",
    "#         ax=ax,\n",
    "#         grid_resolution=50,\n",
    "#         plot_method=\"contour\",\n",
    "#         colors=\"k\",\n",
    "#         levels=[-1, 0, 1],\n",
    "#         alpha=0.5,\n",
    "#         linestyles=[\"--\", \"-\", \"--\"],\n",
    "#     )\n",
    "\n",
    "#     plt.scatter(np_Norm[:, 0], np_Norm[:, 1], c='g', s=10, marker=\"s\", label='Normoxia')\n",
    "#     plt.scatter(np_Hypo[:, 0], np_Hypo[:, 1], c='b', s=10, marker=\"^\", label='Hypoxia')\n",
    "\n",
    "#     # Highligting support Vectors\n",
    "#     supp = np.array(X)[svm_clf[1].support_]\n",
    "\n",
    "#     plt.scatter(      #highlights support vector\n",
    "#     supp[:, 0],\n",
    "#     supp[:, 1],\n",
    "#     s=50,\n",
    "#     linewidth=0.7,\n",
    "#     facecolors=\"none\",\n",
    "#     # alpha=.1,\n",
    "#     edgecolors=\"r\",\n",
    "#     label='Support'\n",
    "#     )\n",
    "\n",
    "#     ax.set_xlabel(Gene1)\n",
    "#     ax.set_ylabel(Gene2)\n",
    "#     plt.title(\"C=\"+str(c))\n",
    "\n",
    "#     plt.legend()\n",
    "#     return {'graph':fig, 'outlier': outlier, 'support': supp}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA + SVC\n",
    "A generalization of the previous model on the whole set of Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PCA_SVC(c=1,file='MCF7'):\n",
    "# #>> Import, Rename, Cleaning Data (Missing XCells train data)\n",
    "#     def renamer(name):\n",
    "#         classification = name.split(\"_\")[-3]\n",
    "#         cell = name.split(\"_\")[-2]\n",
    "#         if len(classification) > 4:\n",
    "#             classification = classification[:4]\n",
    "#         return classification+\"_\"+cell\n",
    "\n",
    "#     filepath_Train = \"raw_data\\\\\"+file+\"_SmartS_Filtered_Normalised_3000_Data_train.txt\"\n",
    "#     df_Train = pd.read_csv(filepath_Train,delimiter=\"\\ \",engine='python',index_col=0)\n",
    "#     df_Train.rename(mapper=renamer, axis='columns', inplace=True)\n",
    "#     df_Train.dropna(axis='rows', inplace = True)\n",
    "\n",
    "# #>> PCA for data visualization\n",
    "#     pca = Pipeline((\n",
    "#                 (\"scaler\", StandardScaler()),\n",
    "#                 ('normalizer',MinMaxScaler()),\n",
    "#                 (\"pca\", PCA(n_components=2)),\n",
    "#             ))\n",
    "#     pca.fit(df_Train.T)\n",
    "#     df_Train_reduced = pd.DataFrame(pca.fit_transform(df_Train.T), columns=pca[\"pca\"].get_feature_names_out(), index=df_Train.columns)\n",
    "#     df_Train_visual = df_Train_reduced.loc[:,[\"pca0\",\"pca1\"]]\n",
    "\n",
    "# #>> Pipeline\n",
    "\n",
    "#     X = df_Train_visual\n",
    "#     y = [int(i.split(\"_\")[0]=='Norm') for i in df_Train.columns]\n",
    "\n",
    "#     svm_clf = Pipeline((\n",
    "#             # (\"scaler\", StandardScaler()),\n",
    "#             # ('normalizer',MinMaxScaler()),\n",
    "#             (\"linear_svc\", SVC(C=c, kernel='linear')),\n",
    "#         ))\n",
    "#     clf = svm_clf.fit(X, y)\n",
    "\n",
    "# #>> Graph\n",
    "\n",
    "#     # Organazing 2 dataset (Hypo & Norm) in np.arrays of 2 dimensions (Gene1 & Gene2)\n",
    "#     # np_Hypo = df_Hypo.loc[[Gene1,Gene2]].to_numpy().transpose()\n",
    "#     # np_Norm = df_Norm.loc[[Gene1,Gene2]].to_numpy().transpose()\n",
    "#     # np_Data = np.concatenate((np_Hypo,np_Norm))\n",
    "\n",
    "#     fig = plt.figure('svm.SVC')\n",
    "#     plt.cla()\n",
    "\n",
    "#     ax = plt.gca()\n",
    "\n",
    "#     DecisionBoundaryDisplay.from_estimator(\n",
    "#         clf,\n",
    "#         df_Train_visual,\n",
    "#         eps = 10,\n",
    "#         ax=ax,\n",
    "#         grid_resolution=50,\n",
    "#         plot_method=\"contour\",\n",
    "#         colors=\"k\",\n",
    "#         levels=[-1, 0, 1],\n",
    "#         alpha=0.5,\n",
    "#         linestyles=[\"--\", \"-\", \"--\"],\n",
    "#     )\n",
    "\n",
    "#     np_Norm = df_Train_visual.loc[[i for i in df_Train_visual.index if 'Norm'==i.split(\"_\")[0]]].to_numpy()\n",
    "#     np_Hypo = df_Train_visual.loc[[i for i in df_Train_visual.index if 'Hypo'==i.split(\"_\")[0]]].to_numpy()\n",
    "#     plt.scatter(np_Norm[:, 0], np_Norm[:, 1], c='g', s=10, marker=\"s\", label='Normoxia')\n",
    "#     plt.scatter(np_Hypo[:, 0], np_Hypo[:, 1], c='b', s=10, marker=\"^\", label='Hypoxia')\n",
    "\n",
    "#     # Highligting support Vectors\n",
    "#     supp = np.array(X)[svm_clf[\"linear_svc\"].support_]\n",
    "\n",
    "#     plt.scatter(      #highlights support vector\n",
    "#     supp[:, 0],\n",
    "#     supp[:, 1],\n",
    "#     s=50,\n",
    "#     linewidth=0.7,\n",
    "#     facecolors=\"none\",\n",
    "#     # alpha=.1,\n",
    "#     edgecolors=\"r\",\n",
    "#     label='Support'\n",
    "#     )\n",
    "\n",
    "#     ax.set_xlabel('PCA 1')\n",
    "#     ax.set_ylabel('PCA 2')\n",
    "#     plt.title(\"C=\"+str(c))\n",
    "\n",
    "#     plt.legend()\n",
    "#     return {'graph':fig, 'model': clf}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### GUI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Widget SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def widget_SVC(): \n",
    "#     plt.ioff()\n",
    "\n",
    "#     dropdown = widgets.Dropdown(\n",
    "#         options=['HCC1806', 'MCF7', 'XCells'],\n",
    "#         value='MCF7',\n",
    "#         description='File:',\n",
    "#     )\n",
    "\n",
    "#     slider = FloatSlider(\n",
    "#         orientation='horizontal',\n",
    "#         description='C value:',\n",
    "#         value=1,\n",
    "#         min=0.2,\n",
    "#         max=100,\n",
    "#         step=0.2\n",
    "#     )\n",
    "\n",
    "#     out = widgets.Output()\n",
    "\n",
    "#     slider.layout.width = '40%'\n",
    "\n",
    "#     svm_output = _SVC(c=slider.value)\n",
    "#     fig = svm_output['graph']\n",
    "#     with out:\n",
    "#         print(str(len(svm_output['outlier']))+\" outliers: {}\".format(svm_output['outlier']))\n",
    "#         print(str(len(svm_output['support']))+\" support vectors\")\n",
    "#     fig.canvas.resizable = False\n",
    "#     # fig.canvas.header_visible = False\n",
    "#     # fig.canvas.toolbar_position = 'top'\n",
    "#     fig.canvas.layout.min_height = '400px'\n",
    "#     plt.title(dropdown.value+' & C = {}'.format(slider.value))\n",
    "\n",
    "#     def update_lines(change):\n",
    "#         outlier = _SVC(c=change.new, file=dropdown.value)['outlier']\n",
    "#         support = _SVC(c=change.new, file=dropdown.value)['support']\n",
    "#         out.clear_output()\n",
    "#         with out:\n",
    "#             print(str(len(outlier))+\" outliers: {}\".format(outlier))\n",
    "#             print(str(len(support))+\" support vectors\")\n",
    "#         plt.title(dropdown.value+' & C = {}'.format(change.new))\n",
    "#         fig.canvas.draw()\n",
    "#         fig.canvas.flush_events()\n",
    "\n",
    "#     def update_file(change):\n",
    "#         if change.new == 'XCells':\n",
    "#             out.clear_output()\n",
    "#             dropdown.value = change.old\n",
    "#             with out:\n",
    "#                 print(\"\\n! - '\"+change.new+\"' file missing in folder 'raw_data\\\\' - !\\n\")\n",
    "#             return\n",
    "#         outlier = _SVC(c=slider.value, file=change.new)['outlier']\n",
    "#         support = _SVC(c=slider.value, file=change.new)['support']\n",
    "#         out.clear_output()\n",
    "#         with out:\n",
    "#             print(str(len(outlier))+\" outliers: {}\".format(outlier))\n",
    "#             print(str(len(support))+\" support vectors\")\n",
    "#         plt.title(change.new+' & C = {}'.format(slider.value))\n",
    "#         fig.canvas.draw()\n",
    "#         fig.canvas.flush_events()\n",
    "\n",
    "#     slider.observe(update_lines, names='value')\n",
    "#     dropdown.observe(update_file, names='value')\n",
    "\n",
    "#     return AppLayout(\n",
    "#             header=dropdown,\n",
    "#             left_sidebar=fig.canvas,\n",
    "#             center=out,\n",
    "#             footer=slider,\n",
    "#             pane_heights=[0, 6, 1],\n",
    "#             pane_widths=[6, 6, 3]\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget_SVC()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Widget PCA + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def widget_PCA_SVC(): \n",
    "#     plt.ioff()\n",
    "\n",
    "#     dropdown = widgets.Dropdown(\n",
    "#         options=['HCC1806', 'MCF7', 'XCells'],\n",
    "#         value='MCF7',\n",
    "#         description='File:',\n",
    "#     )\n",
    "\n",
    "#     slider = FloatSlider(\n",
    "#         orientation='horizontal',\n",
    "#         description='C value:',\n",
    "#         value=1,\n",
    "#         min=0.2,\n",
    "#         max=100,\n",
    "#         step=0.2\n",
    "#     )\n",
    "\n",
    "#     out = widgets.Output()\n",
    "\n",
    "#     slider.layout.width = '40%'\n",
    "\n",
    "#     svm_output = PCA_SVC(c=slider.value)\n",
    "#     fig = svm_output['graph']\n",
    "#     # with out:\n",
    "#         # print(str(len(svm_output['outlier']))+\" outliers: {}\".format(svm_output['outlier']))\n",
    "#         # print(str(len(svm_output['support']))+\" support vectors\")\n",
    "#     fig.canvas.resizable = False\n",
    "#     # fig.canvas.header_visible = False\n",
    "#     # fig.canvas.toolbar_position = 'top'\n",
    "#     fig.canvas.layout.min_height = '400px'\n",
    "#     plt.title(dropdown.value+' & C = {}'.format(slider.value))\n",
    "\n",
    "#     def update_lines(change):\n",
    "#         # outlier = PCA_SVC(c=change.new, file=dropdown.value)['outlier']\n",
    "#         # support = PCA_SVC(c=change.new, file=dropdown.value)['support']\n",
    "#         PCA_SVC(c=change.new, file=dropdown.value)\n",
    "#         out.clear_output()\n",
    "#         # with out:\n",
    "#         #     print(str(len(outlier))+\" outliers: {}\".format(outlier))\n",
    "#         #     print(str(len(support))+\" support vectors\")\n",
    "#         plt.title(dropdown.value+' & C = {}'.format(change.new))\n",
    "#         fig.canvas.draw()\n",
    "#         fig.canvas.flush_events()\n",
    "\n",
    "#     def update_file(change):\n",
    "#         if change.new == 'XCells':\n",
    "#             out.clear_output()\n",
    "#             dropdown.value = change.old\n",
    "#             with out:\n",
    "#                 print(\"\\n! - '\"+change.new+\"' file missing in folder 'raw_data\\\\' - !\\n\")\n",
    "#             return\n",
    "#         # outlier = PCA_SVC(c=slider.value, file=change.new)['outlier']\n",
    "#         # support = PCA_SVC(c=slider.value, file=change.new)['support']\n",
    "#         PCA_SVC(c=slider.value, file=change.new)\n",
    "#         out.clear_output()\n",
    "#         # with out:\n",
    "#         #     print(str(len(outlier))+\" outliers: {}\".format(outlier))\n",
    "#         #     print(str(len(support))+\" support vectors\")\n",
    "#         plt.title(change.new+' & C = {}'.format(slider.value))\n",
    "#         fig.canvas.draw()\n",
    "#         fig.canvas.flush_events()\n",
    "\n",
    "#     slider.observe(update_lines, names='value')\n",
    "#     dropdown.observe(update_file, names='value')\n",
    "\n",
    "#     layout = AppLayout(\n",
    "#         header=dropdown,\n",
    "#         left_sidebar=fig.canvas,\n",
    "#         center=out,\n",
    "#         footer=slider,\n",
    "#         pane_heights=[0, 6, 1],\n",
    "#         pane_widths=[6, 6, 3]\n",
    "#     )\n",
    "#     display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget_PCA_SVC()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score\n",
    "Missing Test file with classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import dataset\n",
    "\n",
    "# def renamer(name):\n",
    "#         classification = name.split(\"_\")[-3]\n",
    "#         cell = name.split(\"_\")[-2]\n",
    "#         if len(classification) > 4:\n",
    "#             classification = classification[:4]\n",
    "#         return classification+\"_\"+cell\n",
    "\n",
    "# filepath_MCF_Test = \"raw_data\\MCF7_SmartS_Filtered_Normalised_3000_Data_test_anonim.txt\"\n",
    "# df_Test = pd.read_csv(filepath_MCF_Test,delimiter=\"\\ \",engine='python',index_col=0)\n",
    "# # print(\"Dataframe dimensions:\", np.shape(df_Test))\n",
    "\n",
    "# df_Test.rename(mapper=renamer, axis='columns', inplace=True)\n",
    "# df_Test.dropna(axis='rows', inplace = True)\n",
    "\n",
    "# pca = Pipeline((\n",
    "#             (\"scaler\", StandardScaler()),\n",
    "#             ('normalizer',MinMaxScaler()),\n",
    "#             (\"pca\", PCA(n_components=2)),\n",
    "#         ))\n",
    "# pca.fit(df_Test.T)\n",
    "# df_Train_reduced = pd.DataFrame(pca.fit_transform(df_Test.T), columns=pca[\"pca\"].get_feature_names_out(), index=df_Test.columns)\n",
    "# df_Train_visual = df_Train_reduced.loc[:,[\"pca0\",\"pca1\"]]\n",
    "\n",
    "\n",
    "# X_test = df_Train_visual\n",
    "# y_test = [int(i.split(\"_\")[0]=='Norm') for i in df_Test.columns]\n",
    "\n",
    "\n",
    "# trained_model = PCA_SVC()['model']\n",
    "# trained_model.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_SVC_Test(d, c=1,file='MCF7'):\n",
    "#>> Import, Rename, Cleaning Data (Missing XCells train data)\n",
    "    def renamer(name):\n",
    "        classification = name.split(\"_\")[-3]\n",
    "        cell = name.split(\"_\")[-2]\n",
    "        if len(classification) > 4:\n",
    "            classification = classification[:4]\n",
    "        return classification+\"_\"+cell\n",
    "\n",
    "    # Train\n",
    "    filepath_Train = \"raw_data\\\\\"+file+\"_SmartS_Filtered_Normalised_3000_Data_train.txt\"\n",
    "    df_Train = pd.read_csv(filepath_Train,delimiter=\"\\ \",engine='python',index_col=0)\n",
    "    df_Train.rename(mapper=renamer, axis='columns', inplace=True)\n",
    "    df_Train.dropna(axis='rows', inplace = True)\n",
    "\n",
    "    # Test\n",
    "    filepath_Test = \"raw_data\\\\\"+file+\"_SmartS_Filtered_Normalised_3000_Data_test_anonim.txt\"\n",
    "    df_Test = pd.read_csv(filepath_Test,delimiter=\"\\ \",engine='python',index_col=0)\n",
    "\n",
    "#>> PCA \n",
    "    pca = Pipeline((\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                ('normalizer',MinMaxScaler()),\n",
    "                (\"pca\", PCA(n_components=d)),\n",
    "            ))\n",
    "    pca.fit(df_Train.T)\n",
    "    df_Train_reduced = pd.DataFrame(pca.fit_transform(df_Train.T), columns=pca[\"pca\"].get_feature_names_out(), index=df_Train.columns)\n",
    "    df_Train_visual = df_Train_reduced.loc[:,[\"pca0\",\"pca1\"]]\n",
    "\n",
    "    pca.fit(df_Test.T)\n",
    "    df_Test_reduced = pd.DataFrame(pca.fit_transform(df_Test.T), columns=pca[\"pca\"].get_feature_names_out(), index=df_Test.columns)\n",
    "    df_Test_visual = df_Test_reduced.loc[:,[\"pca0\",\"pca1\"]]\n",
    "\n",
    "#>> Pipeline\n",
    "\n",
    "    X = df_Train_reduced\n",
    "    y = [int(i.split(\"_\")[0]=='Norm') for i in df_Train.columns]\n",
    "\n",
    "    svm_clf = Pipeline((\n",
    "            # (\"scaler\", StandardScaler()),\n",
    "            # ('normalizer',MinMaxScaler()),\n",
    "            (\"linear_svc\", SVC(C=c, kernel='linear')),\n",
    "        ))\n",
    "    clf = svm_clf.fit(X, y)\n",
    "\n",
    "    y_out = clf.predict(df_Test_reduced)\n",
    "\n",
    "#>> Graph\n",
    "\n",
    "    fig = plt.figure('PCA_SVC: Train + Test')\n",
    "    plt.cla()\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    if d==2:\n",
    "        DecisionBoundaryDisplay.from_estimator(   # Plots decision boundary\n",
    "            clf,\n",
    "            df_Train_visual,\n",
    "            eps = 10,\n",
    "            ax=ax,\n",
    "            grid_resolution=50,\n",
    "            plot_method=\"contour\",\n",
    "            colors=\"k\",\n",
    "            levels=[-1, 0, 1],\n",
    "            alpha=0.5,\n",
    "            linestyles=[\"--\", \"-\", \"--\"],\n",
    "        )\n",
    "\n",
    "    # Plotting Train\n",
    "    np_Norm = df_Train_visual.loc[[i for i in df_Train_visual.index if 'Norm'==i.split(\"_\")[0]]].to_numpy()\n",
    "    np_Hypo = df_Train_visual.loc[[i for i in df_Train_visual.index if 'Hypo'==i.split(\"_\")[0]]].to_numpy()\n",
    "    plt.scatter(np_Norm[:, 0], np_Norm[:, 1], c='g', s=10, marker=\"s\", label='Normoxia')\n",
    "    plt.scatter(np_Hypo[:, 0], np_Hypo[:, 1], c='b', s=10, marker=\"^\", label='Hypoxia')\n",
    "\n",
    "    # Plotting Test\n",
    "    np_Norm_Predicted = df_Test_visual.iloc[[i for i in range(len(y_out)) if y_out[i]==1]].to_numpy()\n",
    "    np_Hypo_Predicted = df_Test_visual.iloc[[i for i in range(len(y_out)) if y_out[i]==0]].to_numpy()\n",
    "    plt.scatter(np_Norm_Predicted[:, 0], np_Norm_Predicted[:, 1], c='g',edgecolors='k', s=40, marker=\"X\", label='Normoxia Test')\n",
    "    plt.scatter(np_Hypo_Predicted[:, 0], np_Hypo_Predicted[:, 1], c='b',edgecolors='k', s=40, marker=\"X\", label='Hypoxia Test')\n",
    "\n",
    "    # Highligting support Vectors\n",
    "    supp = np.array(X)[svm_clf[\"linear_svc\"].support_]\n",
    "\n",
    "    plt.scatter(      #highlights support vector\n",
    "    supp[:, 0],\n",
    "    supp[:, 1],\n",
    "    s=50,\n",
    "    linewidth=0.7,\n",
    "    facecolors=\"none\",\n",
    "    # alpha=.1,\n",
    "    edgecolors=\"r\",\n",
    "    label='Support'\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('PCA 1')\n",
    "    ax.set_ylabel('PCA 2')\n",
    "\n",
    "    plt.legend(loc=1)\n",
    "    return {'graph': fig, 'model': clf, 'max dim': len(y_out), 'support': supp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widget_PCA_SVC_Test(): \n",
    "    plt.ioff()\n",
    "\n",
    "    \n",
    "    dropdown = widgets.Dropdown(\n",
    "        options=['HCC1806', 'MCF7', 'XCells'],\n",
    "        value='MCF7',\n",
    "        description='File:',\n",
    "    )\n",
    "\n",
    "    slider = IntSlider(\n",
    "        orientation='horizontal',\n",
    "        description='Dimensions:',\n",
    "        value=2,\n",
    "        min=2,\n",
    "        max=100,\n",
    "        step=1\n",
    "    )\n",
    "\n",
    "    out = widgets.Output()\n",
    "\n",
    "    slider.layout.width = '40%'\n",
    "\n",
    "    svm_output = PCA_SVC_Test(d=slider.value)\n",
    "    slider.max = svm_output['max dim']\n",
    "    fig = svm_output['graph']\n",
    "\n",
    "    with out:\n",
    "        print(str(len(svm_output['support']))+\" support vectors\")\n",
    "    fig.canvas.resizable = False\n",
    "    # fig.canvas.header_visible = False\n",
    "    # fig.canvas.toolbar_position = 'top'\n",
    "    fig.canvas.layout.min_height = '400px'\n",
    "    plt.title(dropdown.value+' & Dim = {}'.format(slider.value))\n",
    "\n",
    "    def update_dim(change):\n",
    "        svm_output = PCA_SVC_Test(d=change.new, file=dropdown.value)\n",
    "        support = svm_output['support']\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            print(str(len(support))+\" support vectors\")\n",
    "        plt.title(dropdown.value+' & Dim = {}'.format(change.new))\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "    def update_file(change):\n",
    "        if change.new == 'XCells':\n",
    "            out.clear_output()\n",
    "            dropdown.value = change.old\n",
    "            with out:\n",
    "                print(\"\\n! - '\"+change.new+\"' file missing in folder 'raw_data\\\\' - !\\n\")\n",
    "            return\n",
    "        try:\n",
    "            svm_output = PCA_SVC_Test(d=slider.value, file=change.new)\n",
    "        except ValueError:\n",
    "            slider.value = 2\n",
    "            svm_output = PCA_SVC_Test(d=slider.value, file=change.new)\n",
    "        support = svm_output['support']\n",
    "        fig = svm_output['graph']\n",
    "        slider.max = svm_output['max dim']\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            print(str(len(support))+\" support vectors\")\n",
    "        plt.title(change.new+' & Dim = {}'.format(slider.value))\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "    slider.observe(update_dim, names='value')\n",
    "    dropdown.observe(update_file, names='value')\n",
    "\n",
    "    layout = AppLayout(\n",
    "        header=dropdown,\n",
    "        left_sidebar=fig.canvas,\n",
    "        center=out,\n",
    "        footer=slider,\n",
    "        pane_heights=[0, 6, 1],\n",
    "        pane_widths=[6, 6, 3]\n",
    "    )\n",
    "    display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget_PCA_SVC_Test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_SVC_Test_Processed(d, c=1,file='MCF7',kernel='linear'):\n",
    "#>> Import, Rename, Cleaning Data (Missing XCells train data)\n",
    "    def renamer(name):\n",
    "        classification = name.split(\"_\")[-3]\n",
    "        cell = name.split(\"_\")[-2]\n",
    "        if len(classification) > 4:\n",
    "            classification = classification[:4]\n",
    "        return classification+\"_\"+cell\n",
    "\n",
    "    # Train\n",
    "    filepath_Train = \"processed_data\\\\\"+file+\"_SmartS_Filtered_Standardized-Normalised_3000_Data_train.txt\"\n",
    "    df_Train = pd.read_csv(filepath_Train,delimiter=\"\\ \",engine='python',index_col=0)\n",
    "    df_Train.rename(mapper=renamer, axis='columns', inplace=True)\n",
    "    df_Train.dropna(axis='rows', inplace = True)\n",
    "    # print(df_Train.shape)\n",
    "\n",
    "    # Test\n",
    "    filepath_Test = \"processed_data\\\\\"+file+\"_SmartS_Filtered_Standardized-Normalised_3000_Data_test.txt\"\n",
    "    df_Test = pd.read_csv(filepath_Test,delimiter=\"\\ \",engine='python',index_col=0)\n",
    "    df_Test.rename(mapper=renamer, axis='columns', inplace=True)\n",
    "    df_Test.dropna(axis='rows', inplace = True)\n",
    "    # print(df_Test.shape)\n",
    "\n",
    "\n",
    "#>> PCA \n",
    "    pca = Pipeline((\n",
    "                (\"scaler\", StandardScaler()), # only this one is good with only filtered data for linear kernel opposite for rbf\n",
    "                # ('normalizer',MinMaxScaler()),\n",
    "                (\"pca\", PCA(n_components=d)),\n",
    "            ))\n",
    "    pca.fit(df_Train.T)\n",
    "    df_Train_reduced = pd.DataFrame(pca.transform(df_Train.T), columns=pca[\"pca\"].get_feature_names_out(), index=df_Train.columns)\n",
    "    df_Train_visual = df_Train_reduced.loc[:,[\"pca0\",\"pca1\"]]\n",
    "\n",
    "    # pca.fit(df_Test.T)    # do not re-fit ?\n",
    "    df_Test_reduced = pd.DataFrame(pca.transform(df_Test.T), columns=pca[\"pca\"].get_feature_names_out(), index=df_Test.columns) #<<< use transform insted of fit_tranform\n",
    "    df_Test_visual = df_Test_reduced.loc[:,[\"pca0\",\"pca1\"]]\n",
    "\n",
    "#>> Pipeline\n",
    "\n",
    "    X = df_Train_reduced\n",
    "    y = [int(i.split(\"_\")[0]=='Norm') for i in df_Train.columns]\n",
    "\n",
    "    svm_clf = Pipeline((\n",
    "            # (\"scaler\", StandardScaler()),\n",
    "            # ('normalizer',MinMaxScaler()),\n",
    "            (\"linear_svc\", SVC(C=c, kernel=kernel)),\n",
    "        ))\n",
    "    clf = svm_clf.fit(X, y)\n",
    "\n",
    "    y_out = clf.predict(df_Test_reduced)\n",
    "    y_test = [int(i.split(\"_\")[0]=='Norm') for i in df_Test.columns]\n",
    "    score = clf.score(df_Test_reduced, y_test)\n",
    "\n",
    "#>> Graph\n",
    "\n",
    "    fig = plt.figure(f'PCA_SVC: Train + Test (Processed) | {kernel}')\n",
    "    plt.cla()\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    if d==2:\n",
    "        DecisionBoundaryDisplay.from_estimator(   # Plots decision boundary\n",
    "            clf,\n",
    "            df_Train_visual,\n",
    "            eps = 10,\n",
    "            ax=ax,\n",
    "            grid_resolution=50,\n",
    "            plot_method=\"contour\",\n",
    "            colors=\"k\",\n",
    "            levels=[-1, 0, 1],\n",
    "            alpha=0.5,\n",
    "            linestyles=[\"--\", \"-\", \"--\"],\n",
    "        )\n",
    "\n",
    "    # Plotting Train\n",
    "    np_Norm = df_Train_visual.loc[[i for i in df_Train_visual.index if 'Norm'==i.split(\"_\")[0]]].to_numpy()\n",
    "    np_Hypo = df_Train_visual.loc[[i for i in df_Train_visual.index if 'Hypo'==i.split(\"_\")[0]]].to_numpy()\n",
    "    plt.scatter(np_Norm[:, 0], np_Norm[:, 1], c='g', s=10, marker=\"s\", label='Normoxia')\n",
    "    plt.scatter(np_Hypo[:, 0], np_Hypo[:, 1], c='b', s=10, marker=\"^\", label='Hypoxia')\n",
    "\n",
    "    # Plotting Test\n",
    "    np_Norm_Predicted = df_Test_visual.iloc[[i for i in range(len(y_out)) if y_out[i]==1]].to_numpy()\n",
    "    np_Hypo_Predicted = df_Test_visual.iloc[[i for i in range(len(y_out)) if y_out[i]==0]].to_numpy()\n",
    "    plt.scatter(np_Norm_Predicted[:, 0], np_Norm_Predicted[:, 1], c='g',edgecolors='k', s=40, marker=\"X\", label='Normoxia Test')\n",
    "    plt.scatter(np_Hypo_Predicted[:, 0], np_Hypo_Predicted[:, 1], c='b',edgecolors='k', s=40, marker=\"X\", label='Hypoxia Test')\n",
    "\n",
    "    # Highligting support Vectors\n",
    "    supp = np.array(X)[svm_clf[\"linear_svc\"].support_]\n",
    "\n",
    "    plt.scatter(      #highlights support vector\n",
    "    supp[:, 0],\n",
    "    supp[:, 1],\n",
    "    s=50,\n",
    "    linewidth=0.7,\n",
    "    facecolors=\"none\",\n",
    "    # alpha=.1,\n",
    "    edgecolors=\"r\",\n",
    "    label='Support'\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('PCA 1')\n",
    "    ax.set_ylabel('PCA 2')\n",
    "\n",
    "    plt.legend(loc=1)\n",
    "    return {'graph': fig, 'model': clf, 'max dim': df_Train.shape[1], 'support': supp, 'score':score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widget_PCA_SVC_Test_Processed(): \n",
    "    plt.ioff()\n",
    "\n",
    "    \n",
    "    dropdown = widgets.Dropdown(\n",
    "        options=['HCC1806', 'MCF7', 'XCells'],\n",
    "        value='MCF7',\n",
    "        description='File:',\n",
    "    )\n",
    "\n",
    "    slider = IntSlider(\n",
    "        orientation='horizontal',\n",
    "        description='Dimensions:',\n",
    "        value=2,\n",
    "        min=2,\n",
    "        step=1\n",
    "    )\n",
    "\n",
    "    out = widgets.Output()\n",
    "\n",
    "    slider.layout.width = '40%'\n",
    "\n",
    "    svm_output = PCA_SVC_Test_Processed(d=slider.value)\n",
    "    slider.max = svm_output['max dim']\n",
    "    fig = svm_output['graph']\n",
    "\n",
    "    with out:\n",
    "        print(\"Score: {}\".format(svm_output['score']))\n",
    "        print(str(len(svm_output['support']))+\" support vectors\")\n",
    "    fig.canvas.resizable = False\n",
    "    # fig.canvas.header_visible = False\n",
    "    # fig.canvas.toolbar_position = 'top'\n",
    "    fig.canvas.layout.min_height = '400px'\n",
    "    plt.title(dropdown.value+' & Dim = {}'.format(slider.value))\n",
    "\n",
    "    def update_dim(change):\n",
    "        svm_output = PCA_SVC_Test_Processed(d=change.new, file=dropdown.value)\n",
    "        support = svm_output['support']\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            print(\"Score: {}\".format(svm_output['score']))\n",
    "            print(str(len(support))+\" support vectors\")\n",
    "        plt.title(dropdown.value+' & Dim = {}'.format(change.new))\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "    def update_file(change):\n",
    "        if change.new == 'XCells':\n",
    "            out.clear_output()\n",
    "            dropdown.value = change.old\n",
    "            with out:\n",
    "                print(\"\\n! - '\"+change.new+\"' file missing in folder 'raw_data\\\\' - !\\n\")\n",
    "            return\n",
    "        try:\n",
    "            svm_output = PCA_SVC_Test_Processed(d=slider.value, file=change.new)\n",
    "        except ValueError:\n",
    "            slider.value = 2\n",
    "            svm_output = PCA_SVC_Test_Processed(d=slider.value, file=change.new)\n",
    "        support = svm_output['support']\n",
    "        fig = svm_output['graph']\n",
    "        slider.max = svm_output['max dim']\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            print(\"Score: {}\".format(svm_output['score']))\n",
    "            print(str(len(support))+\" support vectors\")\n",
    "        plt.title(change.new+' & Dim = {}'.format(slider.value))\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "    slider.observe(update_dim, names='value')\n",
    "    dropdown.observe(update_file, names='value')\n",
    "\n",
    "    layout = AppLayout(\n",
    "        header=dropdown,\n",
    "        left_sidebar=fig.canvas,\n",
    "        center=out,\n",
    "        footer=slider,\n",
    "        pane_heights=[0, 6, 1],\n",
    "        pane_widths=[6, 6, 3]\n",
    "    )\n",
    "    display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06fb4e2d5a645adaeecb2c9e253c228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(Dropdown(description='File:', index=1, layout=Layout(grid_area='header'), options=('HCC180…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget_PCA_SVC_Test_Processed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime 26m std scaler in PCA part of svm\n",
    "# Runtime 43m std-norm + std scaler in PCA part of svm\n",
    "# Runtime 50m raw from Filtered_Data\n",
    "\n",
    "# plt.ion()\n",
    "# kernel='linear'\n",
    "# for file in ['MCF7','HCC1806']:\n",
    "#     for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "#         out = PCA_SVC_Test_Processed(d=2, file=file, kernel=kernel)\n",
    "#         max_dim = out['max dim']\n",
    "#         # max_dim = 5\n",
    "#         score=[out['score']]\n",
    "\n",
    "#         for d in range(3,max_dim):\n",
    "#             score.append(PCA_SVC_Test_Processed(d=d, file=file, kernel=kernel)['score'])\n",
    "#         plt.cla()\n",
    "#         plt.plot([d for d in range(2,max_dim)],score)\n",
    "#         ax = plt.gca()\n",
    "#         ax.set_xlabel('Dimensions')\n",
    "#         ax.set_ylabel('Score')\n",
    "#         plt.title(file+'_'+kernel)\n",
    "#         # plt.show()\n",
    "#         plt.savefig(\"./Score-Dim_plain_ignore/{}_Std-Norm_{}.png\".format(file, kernel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
